# Task Breakdown - November 14, 2025

## Instructions
**What**: Detailed action steps
**Include**:
- Break each plan item into specific steps
- Add links and resources
- Clear instructions for execution

---

## SUMMARY OF NOVEMBER 14, 2025 SESSION

### Major Accomplishments ‚úÖ
1. **Job Sites File Created:** Initial job sites file (Job —Å–∞–π—Ç—ã.md) created in libraries folder
2. **Data Sources Identified:** Comprehensive list of job sites sources identified (CRM, Google Sheets, email, lead generators)
3. **Integration Plan:** Clear plan established for integrating job sites into taxonomy/library system
4. **Taxonomy Review:** Reviewed taxonomy structure (Actions, Objects, Tools, Professions)
5. **Decision Made:** Communication templates will go to task manager, not libraries

### Critical Issues Identified (Need Immediate Attention) üî¥
1. **Information Gaps** - Data that departments work with for weeks/months but isn't documented in Dropbox
2. **Job Sites Integration** - Need to complete integration into taxonomy structure
3. **Data Collection** - Need systematic approach to collect job sites from all sources

### Next Session Priorities üéØ
1. Complete job sites integration into taxonomy library
2. Begin collecting job sites from CRM and Google Sheets
3. Create comprehensive prompt for deep research of job sites
4. Assist with GitHub Pages setup (if needed)

### Key Participants Identified
- **Artemchuk Nikolay** (ID: 37226) - Project manager, Lead generator | AI | Primary participant
- **Klimenko Yaroslav** (ID: 86478) - Frontend Developer | Dev | Assistance with GitHub Pages
- **Safonova Eleonora** (ID: 87995) - UI/UX designer | Design | AI catalog repository owner
- **Kovalska Anastasiya** (ID: 45405) - Sales Manager, SMM Manager | Sales | Participant
- **Nealova Evgeniya** (ID: 72889) - Recruiter | HR | Participant

### Related Projects
- **Taxonomy/Libraries System** - Knowledge base organization project
- **AI Catalog** - Catalog project (GitHub Pages deployment)

---

## TASK 1: Integrate Job Sites into Taxonomy Library [HIGH PRIORITY]

**Priority:** üî¥ HIGH
**Status:** üî¥ NOT STARTED
**Complexity:** Medium
**Estimated Time:** 2-3 hours
**Owner:** Artemchuk Nikolay (ID: 37226) - AI Department

### Context:
During the November 14 session, an initial job sites file (Job —Å–∞–π—Ç—ã.md) was created in the libraries folder. The next step is to properly integrate this data into the taxonomy/library system so it's accessible and properly structured for AI use.

### What Was Completed:
- ‚úÖ Created initial job sites file: `Job —Å–∞–π—Ç—ã.md` in libraries folder
- ‚úÖ Discussed integration approach and taxonomy structure
- ‚úÖ Reviewed taxonomy components (Actions, Objects, Tools, Professions)

### Steps:
1. Open the job sites file created: `Job —Å–∞–π—Ç—ã.md` in libraries folder
2. Review the taxonomy/library structure to understand integration requirements
3. Identify the appropriate location in taxonomy for job sites data
4. Structure job sites data according to taxonomy format:
   - Organize by categories (if applicable)
   - Add metadata (source, date added, etc.)
   - Link to related taxonomy entities (professions, tools, etc.)
5. Create or update taxonomy index to include job sites reference
6. Verify job sites are accessible through taxonomy structure
7. Test that AI can access and use job sites data from taxonomy
8. Document integration approach for future reference
9. Update related taxonomy documentation if needed

### Resources and Links:
- **Taxonomy Location:** `Dropbox/Nov25/AI/.../taxonomy/` (exact path to be confirmed)
- **Libraries Folder:** Where `Job —Å–∞–π—Ç—ã.md` was created
- **Entities Libraries:** `Entities/Libraries/Prompts` (mentioned in transcript)
- **Task Manager:** Location for related task templates
- **MAIN PROMPT v4.md:** Reference for taxonomy structure and integration guidelines

### Recommended Solution:

**Step 1: Review Taxonomy Structure**
- Navigate to taxonomy folder
- Review existing structure (Actions, Objects, Tools, Professions)
- Understand how entities are organized and linked

**Step 2: Structure Job Sites Data**
```markdown
# Job Sites

## Overview
Comprehensive list of job sites for job postings and candidate sourcing.

## Sources
- CRM System (RH Access)
- Google Sheets
- Email messages
- Lead generators

## Categories
[Organize by type, geography, purpose, etc.]

## Job Sites List
[Structured list with metadata]
```

**Step 3: Create Taxonomy Links**
- Link job sites to relevant professions
- Link to tools used (CRM, Google Sheets, etc.)
- Reference in task manager if applicable

**Step 4: Update Taxonomy Index**
- Add job sites to taxonomy index
- Ensure proper categorization
- Test accessibility

### Testing Checklist:
- [ ] Job sites file properly structured in taxonomy
- [ ] Taxonomy index includes job sites reference
- [ ] Job sites accessible through taxonomy structure
- [ ] Links to related entities (professions, tools) working
- [ ] AI can access job sites data from taxonomy
- [ ] Documentation updated

---

## TASK 2: Expand List of Job Sites [HIGH PRIORITY]

**Priority:** üî¥ HIGH
**Status:** üî¥ NOT STARTED
**Complexity:** Medium
**Estimated Time:** 3-4 hours
**Owner:** Artemchuk Nikolay (ID: 37226) - AI Department

### Context:
During the session, multiple sources for job sites were identified. The goal is to collect a comprehensive list of job sites from all available sources to build a complete database. This is critical because AI cannot help with information it doesn't know about.

### What Was Identified:
- **CRM System:** RH Access - –æ—Ç–∫–ª–∏–∫–∏ —Å–∞–π—Ç–æ–≤ (response sites)
- **Google Sheets:** Used for tracking responses/outreach
- **Email Messages:** Sometimes receive messages from remote job sites
- **Lead Generators:** Automation tools and parsers used by LG department
- **LG Department Resources:** Lead generators work with job sites extensively

### Steps:
1. **Access CRM System (RH Access)**
   - Log into CRM system
   - Navigate to "–æ—Ç–∫–ª–∏–∫–∏ —Å–∞–π—Ç–æ–≤" (response sites) section
   - Extract all job sites listed
   - Document source: "CRM - RH Access"

2. **Access Google Sheets**
   - Open Google Sheets used for response tracking
   - Identify job sites mentioned in the sheets
   - Extract unique job sites
   - Document source: "Google Sheets - [Sheet Name]"

3. **Review Email Messages**
   - Search email for messages from remote job sites
   - Extract job site names and URLs
   - Document source: "Email - [Date/Sender]"

4. **Contact LG Department**
   - Reach out to LG department members
   - Ask about job sites they use
   - Request list of job sites from automation tools/parsers
   - Document source: "LG Department - [Contact Name]"

5. **Research Lead Generator Tools**
   - Identify automation tools used by LG
   - Research job sites integrated in these tools
   - Extract job sites list
   - Document source: "Lead Generator Tools - [Tool Name]"

6. **Consolidate All Sources**
   - Combine all job sites from different sources
   - Remove duplicates
   - Organize by source
   - Add metadata (source, date collected, etc.)

7. **Update Job Sites File**
   - Add new job sites to `Job —Å–∞–π—Ç—ã.md`
   - Maintain source documentation
   - Organize by category if applicable

8. **Verify Completeness**
   - Check if all identified sources have been accessed
   - Verify no obvious sources were missed
   - Document any sources that couldn't be accessed

### Resources and Links:
- **CRM System:** RH Access (login required)
- **Google Sheets:** Location to be confirmed (mentioned in transcript)
- **Email:** Gmail/company email system
- **LG Department:** Contact lead generators for their job sites lists
- **Job Sites File:** `Dropbox/Nov25/AI/.../libraries/Job —Å–∞–π—Ç—ã.md`

### Recommended Approach:

**Source 1: CRM System**
1. Log into CRM (RH Access)
2. Navigate to "–æ—Ç–∫–ª–∏–∫–∏ —Å–∞–π—Ç–æ–≤" section
3. Export or copy job sites list
4. Format: `[Job Site Name] - [URL] - Source: CRM`

**Source 2: Google Sheets**
1. Open relevant Google Sheets
2. Identify columns/rows with job sites
3. Extract unique values
4. Format: `[Job Site Name] - [URL] - Source: Google Sheets - [Sheet Name]`

**Source 3: Email Search**
1. Search email for keywords: "job site", "remote", "hiring platform"
2. Extract job sites from email content
3. Format: `[Job Site Name] - [URL] - Source: Email - [Date]`

**Source 4: LG Department**
1. Contact LG team members
2. Request their job sites lists
3. Ask about automation tools they use
4. Format: `[Job Site Name] - [URL] - Source: LG Department - [Contact]`

**Consolidation:**
- Use spreadsheet or text file to combine all sources
- Remove duplicates (same URL or name)
- Organize by category (geography, type, purpose)
- Add to `Job —Å–∞–π—Ç—ã.md` file

### Testing Checklist:
- [ ] CRM system accessed and job sites extracted
- [ ] Google Sheets reviewed and job sites extracted
- [ ] Email messages searched and job sites found
- [ ] LG department contacted and job sites received
- [ ] All sources documented with metadata
- [ ] Duplicates removed
- [ ] Job sites file updated with new entries
- [ ] Source information maintained for each entry

---

## TASK 3: Create Prompt for Deep Research - Job Sites [HIGH PRIORITY]

**Priority:** üî¥ HIGH
**Status:** üî¥ NOT STARTED
**Complexity:** Medium-High
**Estimated Time:** 2-3 hours
**Owner:** Artemchuk Nikolay (ID: 37226) - AI Department

### Context:
During the session, there was discussion about creating a comprehensive prompt for AI to conduct deep research and find more job sites for job postings and candidates. This prompt should be able to discover job sites based on candidate requirements and reference existing taxonomy data.

### Requirements Identified:
- Include candidate description (Eastern Europe, salary expectations, etc.)
- Reference existing job sites from taxonomy
- Include advanced sorting/classification system
- Link to taxonomy libraries (professions, task manager)
- Structure: Purpose, Vision, Geographic Coverage
- Platform types: Job sites, Communities, Telegram, Facebook, etc.
- Advanced sorting: By Geography, Purpose, Industry Vertical, Candidate Level
- Classification system

### Steps:
1. **Review Existing Prompts in Taxonomy**
   - Navigate to `Entities/Libraries/Prompts` folder
   - Review existing prompt structure (e.g., HR Operations prompt)
   - Understand prompt format and requirements
   - Note: Version, date, criteria, style

2. **Gather Required Context**
   - Copy path to taxonomy folder
   - Copy path to job sites file
   - Copy path to professions library
   - Copy path to task manager
   - Prepare existing job sites list for context

3. **Create Prompt Structure**
   - Title: "Deep Research: Find More Job Sites for Job Postings and Candidates"
   - Include candidate series description
   - Add "Job Sites We Have" section with taxonomy reference
   - Add "Use as a context" instruction
   - Include advanced sorting/classification requirements

4. **Define Candidate Requirements**
   - Create section for candidate description
   - Include: Geographic preferences (Eastern Europe)
   - Include: Salary expectations
   - Include: Other relevant criteria
   - Format as structured input

5. **Add Taxonomy References**
   - Link to job sites in taxonomy
   - Link to professions library
   - Link to task manager
   - Reference Actions, Objects, Tools if relevant

6. **Define Output Requirements**
   - Specify output format
   - Include advanced sorting options
   - Request classification by: Geography, Purpose, Industry, Candidate Level
   - Specify validation criteria

7. **Add Advanced Features**
   - Platform types: Job sites, Communities, Telegram, Facebook, etc.
   - Geographic coverage requirements
   - Industry vertical specifications
   - Candidate level classifications

8. **Test Prompt**
   - Use Claude or ChatGPT to test prompt
   - Verify it produces useful results
   - Refine based on output quality

9. **Save Prompt**
   - Save in appropriate location (Entities/Libraries/Prompts)
   - Follow naming convention
   - Document version and date

### Resources and Links:
- **Taxonomy Location:** `Dropbox/Nov25/AI/.../taxonomy/`
- **Entities/Libraries/Prompts:** `Entities/Libraries/Prompts/`
- **Job Sites File:** `Job —Å–∞–π—Ç—ã.md` in libraries
- **Professions Library:** Taxonomy libraries - professions
- **Task Manager:** Location under libraries
- **Example Prompt:** HR Operations prompt (for structure reference)
- **AI Tools:** Claude, ChatGPT for testing

### Recommended Prompt Structure:

```markdown
# Deep Research: Find More Job Sites for Job Postings and Candidates

## Context
Use as a context:
- Taxonomy: [Copy Path to taxonomy]
- Job Sites We Have: [Copy Path to Job —Å–∞–π—Ç—ã.md]
- Professions: [Copy Path to professions library]
- Task Manager: [Copy Path to task manager]

## Candidate Series Description
[Include candidate requirements:
- Geographic preferences: Eastern Europe
- Salary expectations: [Specify range]
- Other criteria: [Add as needed]
]

## Job Sites We Have
[Reference existing job sites from taxonomy]

## Requirements

### Platform Types
Job sites, Communities, Telegram, Facebook, In Addition To Job sites, In Addition To Web sites

### Structure Required
- Purpose
- Vision
- Geographic Coverage
- Platform Types
- Industry Vertical
- Candidate Level

### Advanced Sorting/Classification System
- By Geography
- By Purpose
- By Industry Vertical
- By Candidate Level

### Output Format
[Specify desired output format]

## Instructions
1. Research and find additional job sites matching candidate requirements
2. Classify each job site using the advanced sorting system
3. Provide structured output with all required fields
4. Reference existing job sites to avoid duplicates
5. Focus on platforms suitable for Eastern Europe candidates
```

### Testing Checklist:
- [ ] Prompt structure follows taxonomy prompt format
- [ ] All required context included (taxonomy, job sites, professions, task manager)
- [ ] Candidate requirements clearly defined
- [ ] Advanced sorting/classification system specified
- [ ] Platform types included
- [ ] Prompt tested with Claude/ChatGPT
- [ ] Output quality verified
- [ ] Prompt saved in correct location
- [ ] Version and date documented

---

## TASK 4: Set Up GitHub Pages Hosting for AI Catalog [MEDIUM PRIORITY]

**Priority:** üü° MEDIUM
**Status:** ‚ö†Ô∏è IN PROGRESS
**Complexity:** Low-Medium
**Estimated Time:** 1-2 hours
**Owner:** Safonova Eleonora (ID: 87995) - Design Department
**Assistance:** Klimenko Yaroslav (ID: 86478) - Dev Department

### Context:
During the session, there was discussion about hosting Eleonora's AI catalog repository on GitHub Pages. The repository exists and contains the catalog code (50% HTML, 50% JavaScript), but needs to be configured for GitHub Pages deployment.

### What Was Discussed:
- Repository exists with AI catalog code
- Needs GitHub Pages configuration
- Should be public repository
- Needs index.html file
- Yaroslav can assist with setup

### Steps:
1. **Verify Repository Status**
   - Confirm repository is on GitHub
   - Check if it's public or private
   - Verify repository contains index.html
   - Check last commit status

2. **Configure GitHub Pages**
   - Navigate to repository Settings
   - Go to Pages section (Settings ‚Üí Pages)
   - Select source branch (usually main or master)
   - Select folder (usually /root)
   - Save settings

3. **Verify Deployment**
   - Wait for GitHub Pages to deploy (usually 1-2 minutes)
   - Check for deployment status
   - Access the published URL
   - Verify site loads correctly

4. **Test Functionality**
   - Test all features of the catalog
   - Verify links work
   - Check responsive design
   - Test on different browsers

5. **Share URL**
   - Copy GitHub Pages URL
   - Share with team
   - Document URL for future reference

### Resources and Links:
- **GitHub Repository:** Eleonora's AI catalog repository
- **GitHub Pages Documentation:** https://docs.github.com/en/pages
- **Repository Settings:** Settings ‚Üí Pages section
- **Assistance:** Yaroslav (Klimenko Yaroslav) - Dev Department

### Recommended Solution:

**Step 1: Access Repository Settings**
1. Go to GitHub repository
2. Click "Settings" tab
3. Scroll to "Pages" section (left sidebar)

**Step 2: Configure Pages**
1. Under "Source", select branch (main/master)
2. Select folder: `/ (root)`
3. Click "Save"

**Step 3: Wait for Deployment**
- GitHub will build and deploy the site
- Usually takes 1-2 minutes
- Check deployment status in Actions tab

**Step 4: Access Site**
- URL format: `https://[username].github.io/[repository-name]`
- Or custom domain if configured
- Test all functionality

### Testing Checklist:
- [ ] Repository is public
- [ ] index.html exists in repository
- [ ] GitHub Pages configured in Settings
- [ ] Deployment successful
- [ ] Site URL accessible
- [ ] All features working
- [ ] Links functional
- [ ] Responsive design works
- [ ] URL shared with team

---

## TASK 5: Identify and Fill Information Gaps [MEDIUM PRIORITY]

**Priority:** üü° MEDIUM
**Status:** üî¥ NOT STARTED
**Complexity:** Medium
**Estimated Time:** Ongoing
**Owner:** Artemchuk Nikolay (ID: 37226) - AI Department

### Context:
During the session, a critical issue was identified: there are information gaps where departments work with data for weeks or months, but this data isn't documented in Dropbox. This prevents AI from accessing and using this information. Job sites were given as an example (worked with for 3+ weeks, not in Dropbox).

### What Was Identified:
- **Information Gaps:** Data used by departments but not in Dropbox
- **Example:** Job sites (3+ weeks of work, not documented)
- **Impact:** AI cannot help with information it doesn't know about
- **Solution:** Systematic identification and documentation of gaps

### Steps:
1. **Review Department Work**
   - Identify what each department works with regularly
   - List tools, platforms, data sources used
   - Note duration of use (weeks, months)

2. **Check Dropbox Documentation**
   - Verify if data is documented in Dropbox
   - Check relevant folders and files
   - Identify what's missing

3. **Create Gap List**
   - Document each identified gap
   - Include: Department, Data Type, Duration, Impact
   - Prioritize by impact and frequency of use

4. **Fill Critical Gaps**
   - Start with high-impact gaps
   - Document data in appropriate Dropbox location
   - Follow taxonomy/library structure if applicable

5. **Establish Process**
   - Create process for ongoing gap identification
   - Set up regular reviews
   - Document new data sources immediately

6. **Update Knowledge Base**
   - Add identified data to appropriate locations
   - Update taxonomy if needed
   - Ensure AI can access new information

### Resources and Links:
- **Dropbox Structure:** `Dropbox/Nov25/[Department]/`
- **Taxonomy/Libraries:** For structured data
- **Department Folders:** For department-specific data
- **MAIN PROMPT v4.md:** For documentation standards

### Recommended Approach:

**Gap Identification Process:**
1. Interview each department
2. Ask: "What data/tools do you use regularly?"
3. Check if it's documented in Dropbox
4. If not, add to gap list

**Gap Documentation:**
- Department: [Department Name]
- Data Type: [Type of data]
- Duration: [How long used]
- Location: [Where it should be documented]
- Priority: [High/Medium/Low]

**Filling Gaps:**
- Create appropriate files/folders
- Document data structure
- Add to taxonomy if applicable
- Update indexes

### Testing Checklist:
- [ ] All departments reviewed
- [ ] Gap list created and prioritized
- [ ] Critical gaps identified
- [ ] High-priority gaps filled
- [ ] Data documented in appropriate locations
- [ ] Process established for ongoing identification
- [ ] Knowledge base updated

---

## Reminder
- Break down each plan into steps
- Add all necessary links and resources
- Write clear execution instructions
- Use AI tools (ChatGPT, Claude) to help with complex problems
- Test thoroughly after each implementation
- Document all changes made

